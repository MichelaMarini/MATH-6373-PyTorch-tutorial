{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOuVfbQqnWB3Agvczect9wB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aIp6co0xKkjg"},"outputs":[],"source":["import numpy as np\n","import torch"]},{"cell_type":"markdown","source":["# Creating tensors using existing data"],"metadata":{"id":"DmkuapPoPrAd"}},{"cell_type":"code","source":["data = np.array([0,1,2])\n","print(data, data.dtype) #check the data type"],"metadata":{"id":"cZy1kTlbKxX6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_T = torch.Tensor(data)\n","print(data_T, data_T.dtype) #it may not preserve the original data type or shape in some cases"],"metadata":{"id":"MKdhd21HK8Lw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_t = torch.tensor(data)\n","print(data_t, data_t.dtype) # it ensures that the resulting tensor has the same data type and shape as the input data"],"metadata":{"id":"9MQvvbnWLagm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**torch.tensor** the created tensor does not share memory with the original NumPy array. It creates a copy of the data.\n","\n","**torch.from_numpy** It creates a tensor that shares the same underlying memory with the NumPy array. It is more memory-efficient as it avoids copying the data.\n","\n","In summary, the main difference is in memory sharing:\n","\n","*   Use *torch.tensor* when you want a new tensor with a copy of the data.\n","*   Use *torch.from_numpy* when you want a tensor that shares the same memory with the NumPy array to save memory and computational cost.\n"],"metadata":{"id":"_TtZHv_XNtW4"}},{"cell_type":"code","source":["data_tensor = torch.from_numpy(data) # specifically designed for NumPy arrays\n","print(data_tensor, data_tensor.dtype)"],"metadata":{"id":"I6xNWU8sMhnD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_tensor_1 = torch.as_tensor(data) #it always avoids creating copy and it can take in any tensor data\n","print(data_tensor_1, data_tensor_1.dtype)"],"metadata":{"id":"HZnAKTdYOtSe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Example of converting dataframe into tensor"],"metadata":{"id":"i7mwJkO4T_Zr"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Create data for the DataFrame\n","data = {\n","    'Person': ['Alice', 'Bob', 'Charlie'],\n","    'The Burger Joint': np.random.randint(0, 6, size=3),\n","    'Whataburger': np.random.randint(0, 6, size=3),\n","    \"McDonald's\": np.random.randint(0, 6, size=3)\n","}\n","\n","# Create the DataFrame\n","df = pd.DataFrame(data)\n","\n","# Extract the numerical values from the DataFrame\n","tensor_data = df.iloc[:, 1:].values\n","\n","# Convert the NumPy array to a PyTorch tensor\n","torch_tensor = torch.tensor(tensor_data)\n","\n","# Display the original DataFrame and the PyTorch tensor\n","print(\"Original DataFrame:\")\n","print(df)\n","\n","print(\"\\nPyTorch Tensor:\")\n","print(torch_tensor)"],"metadata":{"id":"zqZBs8PuUErR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Example of converting image into tensor**\n","\n","\n","\n","*   *transforms.ToTensor()* is specifically designed for converting images to PyTorch tensors with appropriate scaling\n","*   *torch.as_tensor()* is a general-purpose function for creating tensors from various types of data"],"metadata":{"id":"7z582mWUQN5L"}},{"cell_type":"code","source":["from PIL import Image, ImageDraw\n","from IPython.display import display\n","import torchvision.transforms as transforms\n","\n","# Create a new image with a black background\n","width, height = 400, 300\n","background_color = (0, 0, 0)\n","image = Image.new(\"RGB\", (width, height), background_color)\n","\n","# Create a draw object\n","draw = ImageDraw.Draw(image)\n","\n","# Draw a red rectangle on the image\n","rectangle_color = (255, 0, 0)\n","rectangle_coordinates = [(50, 50), (350, 250)]\n","draw.rectangle(rectangle_coordinates, fill=rectangle_color)\n","\n","# Display the image\n","display(image)\n","print(type(image))\n","\n","# Define the transform to convert the image to a PyTorch tensor\n","transform = transforms.ToTensor()\n","\n","# Apply the transform to convert the image to a PyTorch tensor\n","tensor_image = transform(image)\n","\n","# Display the tensor shape\n","print(\"Tensor shape:\", tensor_image.shape) #shape: #of channels, width, heigth"],"metadata":{"id":"RmLi1fIyQAf9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating tensors without existing data"],"metadata":{"id":"gvajifI0P1s4"}},{"cell_type":"code","source":["first_tensor= torch.zeros(4,1)\n","print(\"first\", first_tensor, first_tensor.dtype, first_tensor.shape)\n","\n","second_tensor = torch.ones(2)  #return identity matrix with 2 = number of rows and columns\n","print(\"second\", second_tensor, second_tensor.dtype, second_tensor.shape)\n","\n","\n","third_tensor = torch.eye(3)  #return identity matrix with 3 = number of rows and columns\n","print(\"third\", third_tensor, third_tensor.dtype, third_tensor.shape)\n","\n","\n","fourth_tensor = torch.rand(2,3)\n","print(\"fourth\", fourth_tensor, fourth_tensor.dtype, fourth_tensor.shape)"],"metadata":{"id":"FWX7vSWmUfPR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Task: look at the difference between torch.rand and torch.randn"],"metadata":{"id":"kRUJJp1eZIFP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# specify the dtype\n","new_tensor = torch.tensor(np.array([1,2,3]), dtype=torch.float64)\n","print(new_tensor, new_tensor.shape)"],"metadata":{"id":"hL3xIH6tVp05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Change the dtype\n","# Example 1: Change dtype to float32\n","float32_tensor = new_tensor.to(torch.float32)\n","print(\"Float32 Tensor:\", float32_tensor, float32_tensor.dtype)\n","\n","# Example 2: Change dtype to int64\n","int64_tensor = new_tensor.to(torch.int64)\n","print(\"Int64 Tensor:\", int64_tensor, int64_tensor.dtype)\n","\n","# Example 3: Change dtype to int32\n","int32_tensor = new_tensor.to(torch.int32)\n","print(\"Int32 Tensor:\", int32_tensor)"],"metadata":{"id":"oGN4PdLLWZ5C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test:\n","# 1. Create a numpy array.\n","# 2. Create different PyTorch tensors from the array using different options (torch.Tensor,torch.tensor, torch.as_tensor).\n","# 3. Print the original array and the tensors.\n","# 4. Modify some values in the original array.\n","# 5. Print the modified list and observe how it affects the tensors.\n"],"metadata":{"id":"CQwJTaQcXHNY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tensor operations\n","\n","\n","1.   Reshaping tensors\n","2.   Squeezing and Un-squeezing of tensors\n","3.   Concatenating a tensors\n","4.   Flattening of tensors\n","5.   Arithmetic operations\n","\n"],"metadata":{"id":"UJbaVrh0Y2Hf"}},{"cell_type":"code","source":["# 1. Reshaping tensors\n","\n","# Step 1: Initialize a list with 20 elements\n","original_list = list(range(1, 21))\n","\n","# Step 2: Transform the list into a PyTorch tensor\n","tensor_data = torch.tensor(original_list)\n","\n","# Display the original list and the tensor\n","print(\"Original List:\", original_list)\n","print(\"Tensor:\", tensor_data)\n","\n","# Reshaping Examples:\n","# Example 1: Reshape to a 4x5 matrix\n","reshaped_tensor_4x5 = tensor_data.reshape(4, 5)\n","print(\"\\nReshaped Tensor (4x5):\")\n","print(reshaped_tensor_4x5)\n","\n","# Example 2: Reshape to a 2x10 matrix\n","reshaped_tensor_2x10 = tensor_data.view(2, 10)\n","print(\"\\nReshaped Tensor (2x10):\")\n","print(reshaped_tensor_2x10)\n","\n","\n","#check the size and the shape of the tensor\n","print(\"size, shape:\", reshaped_tensor_4x5.size(), reshaped_tensor_4x5.shape)\n","\n","#check the len of the list\n","print(\"len:\", len(reshaped_tensor_4x5)) #it returns the number of rows\n","\n","#find the number of elements\n","print(\"number of elements:\",reshaped_tensor_4x5.numel())"],"metadata":{"id":"mB82qpI5Y7CC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Squeezing and Un-squeezing of tensors\n","# Example 1: Squeeze operation (remove dimensions with size 1)\n","tensor_data_r = tensor_data.reshape(1,20)\n","squeezed_tensor = tensor_data_r.squeeze()\n","\n","# Example 2: Unsqueeze operation (add a dimension with size 1)\n","unsqueezed_tensor = tensor_data_r.unsqueeze(0)  # Adds a dimension at position 0\n","\n","# Display original, squeezed, and unsqueezed tensors\n","print(\"Original Tensor:\")\n","print(tensor_data_r, tensor_data_r.shape)\n","\n","print(\"\\nSqueezed Tensor:\")\n","print(squeezed_tensor, squeezed_tensor.shape)\n","\n","print(\"\\nUnsqueezed Tensor:\")\n","print(unsqueezed_tensor, unsqueezed_tensor.shape)"],"metadata":{"id":"VcnFTO8eaPAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Concatenating a tensors\n","\n","tensor_1 = torch.tensor([\n","                         [0,1],\n","                         [2,3]])\n","\n","tensor_2 = torch.tensor([\n","                         [4,5],\n","                         [6,7]])\n","# 1) row-wise concatenation\n","conc_tensor = torch.cat((tensor_1,tensor_2), dim=0) # along axis = 0\n","print(\"concatenated tensor:\", conc_tensor, conc_tensor.size())\n","\n","# 2) column-wise concatenation\n","conc_tensor_2 = torch.cat((tensor_1,tensor_2), dim=1) # along axis = 1\n","print(\"concatenated tensor:\", conc_tensor_2, conc_tensor_2.size())\n","\n","tensor_3 = torch.tensor([\n","                        [10,20,30]])\n","print(\"tensor_3:\", tensor_3, tensor_3.size())\n","# to concatenate tensor_1 and tensor_3 the sizes of tensors must match (tensor_1: size 2x2, tensor_3: size 1x3)"],"metadata":{"id":"pfzQfAHyaRlm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. Flattening of tensors\n","tensor_flatten = torch.flatten(tensor_1)\n","print(\"tensor_flatten:\", tensor_flatten, tensor_flatten.size())\n","\n","# try to concatenate tensor_1 and tensor_3\n","new_tensor_1 = torch.unsqueeze((tensor_flatten), dim=0)\n","print(\"new_tensor_1:\", new_tensor_1, new_tensor_1.size())\n","\n","conc_tensor_new = torch.cat((new_tensor_1,tensor_3), dim=1)\n","print(\"conc_tensor_new:\", conc_tensor_new, conc_tensor_new.size())\n","\n","# Transpose tensor_3\n","tensor_3_transposed = tensor_3.t()\n","print(\"tensor_3_transposed:\", tensor_3_transposed, tensor_3_transposed.size())"],"metadata":{"id":"63ltY4_uaTYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. Arithmetic operation\n","\n","# 1) sum\n","print(\"original tensors:\", tensor_1, tensor_2)\n","sum_tensor = tensor_1 + tensor_2 # element-wise operations\n","print(\"sum:\", sum_tensor)\n","\n","# Note: element-wise operations can occur only on same size tensor and is scalar component\n","\n","# 2) subtraction\n","sub_tensor = tensor_1 - tensor_2\n","print(\"subtration:\", sub_tensor)\n","\n","# 3) multiplication\n","mul_tensor= tensor_1*tensor_2\n","print(\"multiplication:\", mul_tensor)\n","\n","# 4) division\n","div_tensor = tensor_1 / tensor_2\n","print(\"division:\", div_tensor)"],"metadata":{"id":"dHFeejL6KGZG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Question: how we can add 11 to the element in position 1,2 of tensor_1?"],"metadata":{"id":"QzVImvB3LOjE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Comparision operations**: it is a type of element-wise comparision, where the result is given out as a boolean of either 0 (False) or 1 (True)\n"],"metadata":{"id":"bnB7J9KGMNzb"}},{"cell_type":"code","source":["t = torch.tensor([[10,20,30],\n","                  [40,50,60]])\n","print(\"t:\", t, t.size())\n","\n","equal_to = t.eq(10)\n","print(\"equal to:\", equal_to)\n","\n","greater_than_equal_to = t.ge(30)\n","print(\"greater than equal to:\", greater_than_equal_to)\n","\n","greater_than = t.gt(30)\n","print(\"greater than:\", greater_than)\n","\n","less_than_equal_to = t.le(20)\n","print(\"less than equal to:\", less_than_equal_to)\n","\n","less_than = t.lt(20)\n","print(\"less than:\", less_than)"],"metadata":{"id":"eFY3R_tWOGih"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Some useful functions:"],"metadata":{"id":"4rNXgpFHRTya"}},{"cell_type":"code","source":["print(\"t:\", t, t.size())\n","\n","# absolute value\n","print(\"abs value:\",t.abs())\n","\n","# square root\n","print(\"square root:\",t.sqrt())\n","\n","# negation\n","print(\"negation:\",t.neg())\n","\n","# mean\n","# to calculate the mean, the tensor dtype must be either a floating point or complex dtype\n","# Convert the tensor to float32\n","t_float = t.float()\n","\n","print(\"mean:\", t_float.mean())\n","\n","#std\n","print(\"std:\", t_float.std())\n","\n","# sum at certain columns/rows\n","print(\"sum row 0:\", t[0].sum())\n","print(\"sum row 1:\", t[1].sum())\n","\n","print(\"sum each row\", t.sum(dim=0))\n","print(\"sum each column\", t.sum(dim=1))\n","\n","# find the max value, min value\n","print(\"max:\", t.max())\n","print(\"max value in row 1:\", t[0].max())\n","print(\"min:\", t.min())\n","print(\"min value in column 1:\", t[:, 0].min())\n","print(\"index of the max value:\", t.argmax()) #it flatten the tensor\n","print(\"index of the max value:\", torch.argmax(t, dim=1).numpy()) #need to specify the dimension"],"metadata":{"id":"oBEdD1IeSOAn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Moving tensors to the GPU\n","\n","PyTorch tensors also can be stored in a different kind of processor: a Graphics Processing Unit (GPU). Every PyTorch tensor can be transferred to (one of) the GPU(s) in order to perform massively parallel, fast computations. All operations that will be performed on the tensor will be carried out using the GPU-specific routines that come with PyTorch."],"metadata":{"id":"DSeuPYscuCLq"}},{"cell_type":"code","source":["!pip3 install torch torchvision"],"metadata":{"id":"nBjycJTlzcvN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import sys\n","\n","#Create a tensor to GPU\n","tensor_gpu = torch.tensor([[1,2,3], [0.1,0.2,0.3]], device='cuda')\n","\n","# Print the memory usage of the tensor 't'\n","print(\"Memory Allocated for 't':\", sys.getsizeof(t) / (1024 ** 2), \"MB\")\n","\n","# Move the tensor to GPU\n","if torch.cuda.is_available():\n","\n","    gpu_tensor = t.to('cuda')\n","    # Alternatively, you can use gpu_tensor = t.cuda()\n","\n","    # Print the tensors to verify the move\n","    print(\"CPU Tensor:\", t)\n","    print(\"GPU Tensor:\", gpu_tensor)\n","\n","     # Check GPU memory usage\n","    print(\"GPU Memory Allocated:\", torch.cuda.memory_allocated() / (1024 ** 2), \"MB\")\n","    print(\"GPU Max Memory Allocated:\", torch.cuda.max_memory_allocated() / (1024 ** 2), \"MB\")\n","\n","else:\n","    print(\"CUDA not available. Unable to move tensor to GPU.\")"],"metadata":{"id":"QTcYl0wMuJ1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example 1: Operations on GPU\n","\n","import time\n","\n","# Create tensors on CPU\n","cpu_tensor1 = torch.randn(1000, 1000)\n","cpu_tensor2 = torch.randn(1000, 1000)\n","\n","# Move tensors to GPU\n","gpu_tensor1 = cpu_tensor1.to('cuda')\n","gpu_tensor2 = cpu_tensor2.to('cuda')\n","\n","# Measure time for element-wise addition on CPU\n","start_time = time.time()\n","result_cpu = cpu_tensor1 + cpu_tensor2\n","print(\"Time on CPU:\", time.time() - start_time)\n","\n","# Measure time for element-wise addition on GPU\n","start_time = time.time()\n","result_gpu = gpu_tensor1 + gpu_tensor2\n","print(\"Time on GPU:\", time.time() - start_time)"],"metadata":{"id":"5mNiZRnIlh9k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example 2: Memory Management\n","\n","# Create tensors on GPU\n","tensor1 = torch.randn(1000, 1000, device='cuda')\n","tensor2 = torch.randn(1000, 1000, device='cuda')\n","\n","# Perform operations on GPU\n","result_tensor = tensor1 + tensor2\n","\n","# Free GPU memory\n","torch.cuda.empty_cache()"],"metadata":{"id":"3QXQb68SltMB"},"execution_count":null,"outputs":[]}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPXq032dBZOwW+UKFL7+mYN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichelaMarini/MATH-6373-PyTorch-tutorial/blob/main/WEEK_1_INTRO_TO_TENSORS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIp6co0xKkjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c04b314-05c9-4766-9520-bd76cdb3473f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating tensors using existing data"
      ],
      "metadata": {
        "id": "DmkuapPoPrAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([0,1,2])\n",
        "print(data, data.dtype) #check the data type"
      ],
      "metadata": {
        "id": "cZy1kTlbKxX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4ac5aa-88e7-4db6-a02f-05e9c3f9ff65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2] int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_T = torch.Tensor(data)\n",
        "print(data_T, data_T.dtype) #it may not preserve the original data type or shape in some cases"
      ],
      "metadata": {
        "id": "MKdhd21HK8Lw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8a0c98-5aad-44ce-8af4-c6e753164d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 2.]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_t = torch.tensor(data)\n",
        "print(data_t, data_t.dtype) # it ensures that the resulting tensor has the same data type and shape as the input data"
      ],
      "metadata": {
        "id": "9MQvvbnWLagm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fcc1f78-f607-4454-c6e0-486d3be38189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**torch.tensor** the created tensor does not share memory with the original NumPy array. It creates a copy of the data.\n",
        "\n",
        "**torch.from_numpy** It creates a tensor that shares the same underlying memory with the NumPy array. It is more memory-efficient as it avoids copying the data.\n",
        "\n",
        "In summary, the main difference is in memory sharing:\n",
        "\n",
        "*   Use *torch.tensor* when you want a new tensor with a copy of the data.\n",
        "*   Use *torch.from_numpy* when you want a tensor that shares the same memory with the NumPy array to save memory and computational cost.\n"
      ],
      "metadata": {
        "id": "_TtZHv_XNtW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_tensor = torch.from_numpy(data) # specifically designed for NumPy arrays\n",
        "print(data_tensor, data_tensor.dtype)"
      ],
      "metadata": {
        "id": "I6xNWU8sMhnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe04d3fe-6a51-4471-ce98-25d46b014315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_tensor_1 = torch.as_tensor(data) #it always avoids creating copy and it can take in any tensor data\n",
        "print(data_tensor_1, data_tensor_1.dtype)"
      ],
      "metadata": {
        "id": "HZnAKTdYOtSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b9efc0-6850-4ce2-e4f2-e2833a2c305d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of converting dataframe into tensor"
      ],
      "metadata": {
        "id": "i7mwJkO4T_Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create data for the DataFrame\n",
        "data = {\n",
        "    'Person': ['Alice', 'Bob', 'Charlie'],\n",
        "    'The Burger Joint': np.random.randint(0, 6, size=3),\n",
        "    'Whataburger': np.random.randint(0, 6, size=3),\n",
        "    \"McDonald's\": np.random.randint(0, 6, size=3)\n",
        "}\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Extract the numerical values from the DataFrame\n",
        "tensor_data = df.iloc[:, 1:].values\n",
        "\n",
        "# Convert the NumPy array to a PyTorch tensor\n",
        "torch_tensor = torch.tensor(tensor_data)\n",
        "\n",
        "# Display the original DataFrame and the PyTorch tensor\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "print(\"\\nPyTorch Tensor:\")\n",
        "print(torch_tensor)"
      ],
      "metadata": {
        "id": "zqZBs8PuUErR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "627c1f06-bbd8-40db-a04b-d2b6b103120b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "    Person  The Burger Joint  Whataburger  McDonald's\n",
            "0    Alice                 0            0           0\n",
            "1      Bob                 5            0           4\n",
            "2  Charlie                 2            3           5\n",
            "\n",
            "PyTorch Tensor:\n",
            "tensor([[0, 0, 0],\n",
            "        [5, 0, 4],\n",
            "        [2, 3, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example of converting image into tensor**\n",
        "\n",
        "\n",
        "\n",
        "*   *transforms.ToTensor()* is specifically designed for converting images to PyTorch tensors with appropriate scaling\n",
        "*   *torch.as_tensor()* is a general-purpose function for creating tensors from various types of data"
      ],
      "metadata": {
        "id": "7z582mWUQN5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw\n",
        "from IPython.display import display\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Create a new image with a black background\n",
        "width, height = 400, 300\n",
        "background_color = (0, 0, 0)\n",
        "image = Image.new(\"RGB\", (width, height), background_color)\n",
        "\n",
        "# Create a draw object\n",
        "draw = ImageDraw.Draw(image)\n",
        "\n",
        "# Draw a red rectangle on the image\n",
        "rectangle_color = (0, 255, 0)\n",
        "rectangle_coordinates = [(50, 50), (350, 250)]\n",
        "draw.rectangle(rectangle_coordinates, fill=rectangle_color)\n",
        "\n",
        "# Display the image\n",
        "display(image)\n",
        "print(type(image))\n",
        "\n",
        "# Define the transform to convert the image to a PyTorch tensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Apply the transform to convert the image to a PyTorch tensor\n",
        "tensor_image = transform(image)\n",
        "\n",
        "# Display the tensor shape\n",
        "print(\"Tensor shape:\", tensor_image.shape) #shape: #of channels, width, heigth"
      ],
      "metadata": {
        "id": "RmLi1fIyQAf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "a54e5366-2f60-4885-930d-776198f5663f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=400x300>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAEsAZADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD1Twf4P0HVfCtle3tj5txJv3v5zrnDsBwGA6AVuf8K/8L/8AQM/8mJf/AIqj4f8A/Ikad/21/wDRjV01fDYvF4iOIqJVGkm+r7n5tjsdio4qrGNWSSk+r7vzOZ/4V/4X/wCgZ/5MS/8AxVH/AAr/AML/APQM/wDJiX/4qumorn+u4n/n5L72cv8AaGM/5+y/8Cf+ZzP/AAr/AML/APQM/wDJiX/4qj/hX/hf/oGf+TEv/wAVXTUUfXcT/wA/Jfew/tDGf8/Zf+BP/M5n/hX/AIX/AOgZ/wCTEv8A8VR/wr/wv/0DP/JiX/4qumoo+u4n/n5L72H9oYz/AJ+y/wDAn/mcz/wr/wAL/wDQM/8AJiX/AOKo/wCFf+F/+gZ/5MS//FV01FH13E/8/Jfew/tDGf8AP2X/AIE/8zmf+Ff+F/8AoGf+TEv/AMVR/wAK/wDC/wD0DP8AyYl/+KrpqKPruJ/5+S+9h/aGM/5+y/8AAn/mcz/wr/wv/wBAz/yYl/8AiqP+Ff8Ahf8A6Bn/AJMS/wDxVdNRR9dxP/PyX3sP7Qxn/P2X/gT/AMzmf+Ff+F/+gZ/5MS//ABVH/Cv/AAv/ANAz/wAmJf8A4qumoo+u4n/n5L72H9oYz/n7L/wJ/wCZzP8Awr/wv/0DP/JiX/4qj/hX/hf/AKBn/kxL/wDFV01FH13E/wDPyX3sP7Qxn/P2X/gT/wAzmf8AhX/hf/oGf+TEv/xVH/Cv/C//AEDP/JiX/wCKrpqKPruJ/wCfkvvYf2hjP+fsv/An/mcz/wAK/wDC/wD0DP8AyYl/+Ko/4V/4X/6Bn/kxL/8AFV01FH13E/8APyX3sP7Qxn/P2X/gT/zOZ/4V/wCF/wDoGf8AkxL/APFUf8K/8L/9Az/yYl/+KrpqKPruJ/5+S+9h/aGM/wCfsv8AwJ/5nM/8K/8AC/8A0DP/ACYl/wDiqP8AhX/hf/oGf+TEv/xVdNRR9dxP/PyX3sP7Qxn/AD9l/wCBP/M5n/hX/hf/AKBn/kxL/wDFUf8ACv8Awv8A9Az/AMmJf/iq6aij67if+fkvvYf2hjP+fsv/AAJ/5nM/8K/8L/8AQM/8mJf/AIqj/hX/AIX/AOgZ/wCTEv8A8VXTUUfXcT/z8l97D+0MZ/z9l/4E/wDM5n/hX/hf/oGf+TEv/wAVR/wr/wAL/wDQM/8AJiX/AOKrpqKPruJ/5+S+9h/aGM/5+y/8Cf8Amcz/AMK/8L/9Az/yYl/+Ko/4V/4X/wCgZ/5MS/8AxVdNRR9dxP8Az8l97D+0MZ/z9l/4E/8AM5n/AIV/4X/6Bn/kxL/8VR/wr/wv/wBAz/yYl/8Aiq6aij67if8An5L72H9oYz/n7L/wJ/5nM/8ACv8Awv8A9Az/AMmJf/iqo614H8OWmhajcwadsmhtpJEbz5DhgpIOC3rXaVmeI/8AkWNW/wCvKb/0A1pRxmJdSKdSW66s1oY/FurFOrLdfaff1PnyiiivvT9OCiiigAooooAKKKKACiiigAooooA9w+H/APyJGnf9tf8A0Y1dNXM/D/8A5EjTv+2v/oxq6avz7G/7zU/xP8z8szH/AHyr/il+bCiiiuU4wooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKzPEf/ACLGrf8AXlN/6Aa06zPEf/Isat/15Tf+gGtaP8WPqjbD/wAaHqvzPnyiiiv0Y/WQooooAKKKKACiiigAooooAKKKKAPcPh//AMiRp3/bX/0Y1dNXM/D/AP5EjTv+2v8A6Maumr8+xv8AvNT/ABP8z8szH/fKv+KX5sKKKK5TjCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArM8R/8ixq3/XlN/6Aa06zPEf/ACLGrf8AXlN/6Aa1o/xY+qNsP/Gh6r8z58ooor9GP1kKKKKACiiigAooooAKKKKACiiigD3D4f8A/Ikad/21/wDRjV01cz8P/wDkSNO/7a/+jGrpq/Psb/vNT/E/zPyzMf8AfKv+KX5sKKKK5TjCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArM8R/8AIsat/wBeU3/oBrTrM8R/8ixq3/XlN/6Aa1o/xY+qNsP/ABoeq/M+fKKKK/Rj9ZCiiigAooooAKKKKACiiigAooooA9w+H/8AyJGnf9tf/RjV01cz8P8A/kSNO/7a/wDoxq6avz7G/wC81P8AE/zPyzMf98q/4pfmwooorlOMKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACszxH/yLGrf9eU3/oBrTrM8R/8AIsat/wBeU3/oBrWj/Fj6o2w/8aHqvzPnyiiiv0Y/WQooooAKKKKACiiigAooooAKKKKAPcPh/wD8iRp3/bX/ANGNXTVzPw//AORI07/tr/6Maumr8+xv+81P8T/M/LMx/wB8q/4pfmwooorlOMKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACszxH/wAixq3/AF5Tf+gGtOszxH/yLGrf9eU3/oBrWj/Fj6o2w/8AGh6r8z58ooor9GP1kKKKKACiiigAooooAKKKKACiiigD3D4f/wDIkad/21/9GNXTVzPw/wD+RI07/tr/AOjGrpq/Psb/ALzU/wAT/M/LMx/3yr/il+bCiiiuU4wooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKzPEf/Isat/15Tf+gGtOszxH/wAixq3/AF5Tf+gGtaP8WPqjbD/xoeq/M+fKKKK/Rj9ZCiiigAooooAKKKKACiiigAooooA9w+H/APyJGnf9tf8A0Y1dNXM/D/8A5EjTv+2v/oxq6avz7G/7zU/xP8z8szH/AHyr/il+bCiiiuU4wooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKzPEf/ACLGrf8AXlN/6Aa06zPEf/Isat/15Tf+gGtaP8WPqjbD/wAaHqvzPnyiiiv0Y/WQooooAKKKKACiiigAooooAKKKKAPcPh//AMiRp3/bX/0Y1dNXM/D/AP5EjTv+2v8A6Maumr8+xv8AvNT/ABP8z8szH/fKv+KX5sKKKK5TjCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArM8R/8ixq3/XlN/6Aa06zPEf/ACLGrf8AXlN/6Aa1o/xY+qNsP/Gh6r8z58ooor9GP1kKKKKACiiigAooooAKKKKACiiigD3D4f8A/Ikad/21/wDRjV01cz8P/wDkSNO/7a/+jGrpq/Psb/vNT/E/zPyzMf8AfKv+KX5sKKKK5TjCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArM8R/8AIsat/wBeU3/oBrTrM8R/8ixq3/XlN/6Aa1o/xY+qNsP/ABoeq/M+fKKKK/Rj9ZCiiigAooooAKKKKACiiigAooooA9w+H/8AyJGnf9tf/RjV01cz8P8A/kSNO/7a/wDoxq6avz7G/wC81P8AE/zPyzMf98q/4pfmwooorlOMKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACszxH/yLGrf9eU3/oBrTrM8R/8AIsat/wBeU3/oBrWj/Fj6o2w/8aHqvzPnyiiiv0Y/WQooooAKKKKACiiigAooooAKKKKAPcPh/wD8iRp3/bX/ANGNXTVzPw//AORI07/tr/6Maumr8+xv+81P8T/M/LMx/wB8q/4pfmwooorlOMKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACszxH/wAixq3/AF5Tf+gGtOszxH/yLGrf9eU3/oBrWj/Fj6o2w/8AGh6r8z58ooor9GP1kKKKKACiiigAooooAKKKKACiiigD3D4f/wDIkad/21/9GNXTV4no/j/VdE0qHTra3snhh3bWkRixyxY5ww7mr3/C1Nc/59dO/wC/b/8AxdfJYnJ8VUrTnFKzbe/mfDYvIMZVxFSpFKzbe/dnr1FeQ/8AC1Nc/wCfXTv+/b//ABdH/C1Nc/59dO/79v8A/F1j/YeL7L7zn/1cx3ZfeevUV5D/AMLU1z/n107/AL9v/wDF0f8AC1Nc/wCfXTv+/b//ABdH9h4vsvvD/VzHdl9569RXkP8AwtTXP+fXTv8Av2//AMXR/wALU1z/AJ9dO/79v/8AF0f2Hi+y+8P9XMd2X3nr1FeQ/wDC1Nc/59dO/wC/b/8AxdH/AAtTXP8An107/v2//wAXR/YeL7L7w/1cx3ZfeevUV5D/AMLU1z/n107/AL9v/wDF0f8AC1Nc/wCfXTv+/b//ABdH9h4vsvvD/VzHdl9569RXkP8AwtTXP+fXTv8Av2//AMXR/wALU1z/AJ9dO/79v/8AF0f2Hi+y+8P9XMd2X3nr1FeQ/wDC1Nc/59dO/wC/b/8AxdH/AAtTXP8An107/v2//wAXR/YeL7L7w/1cx3ZfeevUV5D/AMLU1z/n107/AL9v/wDF0f8AC1Nc/wCfXTv+/b//ABdH9h4vsvvD/VzHdl9569RXkP8AwtTXP+fXTv8Av2//AMXR/wALU1z/AJ9dO/79v/8AF0f2Hi+y+8P9XMd2X3nr1FeQ/wDC1Nc/59dO/wC/b/8AxdH/AAtTXP8An107/v2//wAXR/YeL7L7w/1cx3ZfeevUV5D/AMLU1z/n107/AL9v/wDF0f8AC1Nc/wCfXTv+/b//ABdH9h4vsvvD/VzHdl9569RXkP8AwtTXP+fXTv8Av2//AMXR/wALU1z/AJ9dO/79v/8AF0f2Hi+y+8P9XMd2X3nr1FeQ/wDC1Nc/59dO/wC/b/8AxdH/AAtTXP8An107/v2//wAXR/YeL7L7w/1cx3ZfeevUV5D/AMLU1z/n107/AL9v/wDF0f8AC1Nc/wCfXTv+/b//ABdH9h4vsvvD/VzHdl9569RXkP8AwtTXP+fXTv8Av2//AMXR/wALU1z/AJ9dO/79v/8AF0f2Hi+y+8P9XMd2X3nr1FeQ/wDC1Nc/59dO/wC/b/8AxdH/AAtTXP8An107/v2//wAXR/YeL7L7w/1cx3ZfeevUV5D/AMLU1z/n107/AL9v/wDF0f8AC1Nc/wCfXTv+/b//ABdH9h4vsvvD/VzHdl9569WZ4j/5FjVv+vKb/wBANeaf8LU1z/n107/v2/8A8XUF78SdZv7C4s5bawEc8TRMVjfIDAg4+brzV08lxUZqTS0fc0o8PY2FSMmlo11OOooor7A+9CiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA/9k=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'PIL.Image.Image'>\n",
            "Tensor shape: torch.Size([3, 300, 400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🐧 Converting a DataFrame to a PyTorch Tensor  \n",
        "\n",
        "In this exercise, you will work with the **penguins** dataset, which is available in the `seaborn` library and can be found [here](https://github.com/mwaskom/seaborn-data/blob/master/penguins.csv).  \n",
        "\n",
        "## **Instructions**  \n",
        "1. **Import the necessary libraries**: You will need `seaborn`, `pandas`, and `torch`.  \n",
        "2. **Load the dataset**: Use `sns.load_dataset(\"penguins\")` to load the dataset into a pandas DataFrame.  \n",
        "3. **Print the data types of each column** before and after handling missing values.  \n",
        "4. **Handle missing values**: Remove any rows that contain NaN values using `dropna()`.  \n",
        "5. **Select numerical columns only**: Extract columns with numeric data types (`float64` and `int64`).  \n",
        "6. **Convert the DataFrame to a PyTorch tensor**: Use `torch.tensor()` to transform the numerical data into a tensor with `dtype=torch.float32`.  \n",
        "7. **Print the shape of the resulting tensor** to verify its dimensions.  \n",
        "\n"
      ],
      "metadata": {
        "id": "QtxoPaisjupi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1-3: Load the dataset, print the dataset\n",
        "df = sns.load_dataset(\"penguins\")\n",
        "sns.histplot(data=df, x=\"flipper_length_mm\", hue=\"species\", multiple=\"stack\")\n",
        "\n",
        "# Step 4: Drop missing values\n",
        "\n",
        "# Step 5: Select numerical columns\n",
        "\n",
        "\n",
        "# Step 6: Convert to PyTorch tensor\n",
        "\n",
        "\n",
        "# Step 7: Print the shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3_3GV_aAixDx",
        "outputId": "3ccef8a3-d0b8-4d33-8495-bc21e2cc127e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
            "0    Adelie  Torgersen            39.1           18.7              181.0   \n",
            "1    Adelie  Torgersen            39.5           17.4              186.0   \n",
            "2    Adelie  Torgersen            40.3           18.0              195.0   \n",
            "3    Adelie  Torgersen             NaN            NaN                NaN   \n",
            "4    Adelie  Torgersen            36.7           19.3              193.0   \n",
            "..      ...        ...             ...            ...                ...   \n",
            "339  Gentoo     Biscoe             NaN            NaN                NaN   \n",
            "340  Gentoo     Biscoe            46.8           14.3              215.0   \n",
            "341  Gentoo     Biscoe            50.4           15.7              222.0   \n",
            "342  Gentoo     Biscoe            45.2           14.8              212.0   \n",
            "343  Gentoo     Biscoe            49.9           16.1              213.0   \n",
            "\n",
            "     body_mass_g     sex  \n",
            "0         3750.0    Male  \n",
            "1         3800.0  Female  \n",
            "2         3250.0  Female  \n",
            "3            NaN     NaN  \n",
            "4         3450.0  Female  \n",
            "..           ...     ...  \n",
            "339          NaN     NaN  \n",
            "340       4850.0  Female  \n",
            "341       5750.0    Male  \n",
            "342       5200.0  Female  \n",
            "343       5400.0    Male  \n",
            "\n",
            "[344 rows x 7 columns]\n",
            "species               object\n",
            "island                object\n",
            "bill_length_mm       float64\n",
            "bill_depth_mm        float64\n",
            "flipper_length_mm    float64\n",
            "body_mass_g          float64\n",
            "sex                   object\n",
            "dtype: object\n",
            "torch.Size([333, 4])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating tensors without existing data"
      ],
      "metadata": {
        "id": "gvajifI0P1s4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_tensor= torch.zeros(4,1)\n",
        "print(\"first\", first_tensor, first_tensor.dtype, first_tensor.shape)\n",
        "\n",
        "second_tensor = torch.ones(2)  #return with 2 = number of rows and columns\n",
        "print(\"second\", second_tensor, second_tensor.dtype, second_tensor.shape)\n",
        "\n",
        "\n",
        "third_tensor = torch.eye(3)  #return identity matrix with 3 = number of rows and columns\n",
        "print(\"third\", third_tensor, third_tensor.dtype, third_tensor.shape)\n",
        "\n",
        "\n",
        "fourth_tensor = torch.rand(2,3)\n",
        "print(\"fourth\", fourth_tensor, fourth_tensor.dtype, fourth_tensor.shape)"
      ],
      "metadata": {
        "id": "FWX7vSWmUfPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea880649-af1c-4aa4-c222-5c5d27e469b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]]) torch.float32 torch.Size([4, 1])\n",
            "second tensor([1., 1.]) torch.float32 torch.Size([2])\n",
            "third tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]]) torch.float32 torch.Size([3, 3])\n",
            "fourth tensor([[0.2502, 0.0203, 0.4245],\n",
            "        [0.0035, 0.8579, 0.5552]]) torch.float32 torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task: look at the difference between torch.rand and torch.randn\n",
        "\n",
        "\n",
        "1.  torch.rand: Generates random numbers from a uniform distribution between 0 and 1. This means the values will be evenly distributed between 0 and 1, with no bias towards any specific value in that range.\n",
        "\n",
        "2.  torch.randn: Generates random numbers from a normal (Gaussian) distribution with a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a02QOoNunO-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the dtype\n",
        "new_tensor = torch.tensor(np.array([1,2,3]), dtype=torch.float64)\n",
        "print(new_tensor, new_tensor.shape)"
      ],
      "metadata": {
        "id": "hL3xIH6tVp05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85ae64a-3cde-444a-c86c-ee5a71470942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.], dtype=torch.float64) torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the dtype\n",
        "# Example 1: Change dtype to float32\n",
        "float32_tensor = new_tensor.to(torch.float32)\n",
        "print(\"Float32 Tensor:\", float32_tensor, float32_tensor.dtype)\n",
        "\n",
        "# Example 2: Change dtype to int64\n",
        "int64_tensor = new_tensor.to(torch.int64)\n",
        "print(\"Int64 Tensor:\", int64_tensor, int64_tensor.dtype)\n",
        "\n",
        "# Example 3: Change dtype to int32\n",
        "int32_tensor = new_tensor.to(torch.int32)\n",
        "print(\"Int32 Tensor:\", int32_tensor)"
      ],
      "metadata": {
        "id": "oGN4PdLLWZ5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671b9e79-efd0-4e71-d243-a34e384d6239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float32 Tensor: tensor([1., 2., 3.]) torch.float32\n",
            "Int64 Tensor: tensor([1, 2, 3]) torch.int64\n",
            "Int32 Tensor: tensor([1, 2, 3], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test: Working with NumPy Arrays and PyTorch Tensors\n",
        "Steps:\n",
        "\n",
        "\n",
        "1.   Create a NumPy array: Start by creating a simple NumPy array.\n",
        "2.   Create different PyTorch tensors: Use different methods to create PyTorch tensors from the NumPy array: torch.Tensor(), torch.tensor(), and torch.as_tensor()\n",
        "\n",
        "3. Print the original array and the tensors: Display the NumPy array and the tensors created using the different methods.\n",
        "4. Modify the original array: Change some values in the original NumPy array.\n",
        "5. Print the modified array: Display the modified array and observe how it affects the tensors created earlier.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ctj-baQ9oaSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a numpy array.\n",
        "# 2. Create different PyTorch tensors from the array using different options (torch.Tensor,torch.tensor, torch.as_tensor).\n",
        "# 3. Print the original array and the tensors.\n",
        "# 4. Modify some values in the original array.\n",
        "# 5. Print the modified array and observe how it affects the tensors.\n",
        "\n",
        "#step 1\n",
        "original_array = np.array([0,1,2,3,4])\n",
        "#step 2\n",
        "\n",
        "#step 3\n",
        "#step 4\n",
        "\n",
        "#step 5"
      ],
      "metadata": {
        "id": "CQwJTaQcXHNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83226bf4-20c7-4029-fcf3-4f3b0f865357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orig: [0 1 2 3 4]\n",
            "1: tensor([0, 1, 2, 3, 4])\n",
            "2 tensor([0., 1., 2., 3., 4.])\n",
            "3: tensor([0, 1, 2, 3, 4])\n",
            "mod: [   0    1    0    3 1000]\n",
            "1: tensor([0, 1, 2, 3, 4])\n",
            "2 tensor([0., 1., 2., 3., 4.])\n",
            "3: tensor([   0,    1,    0,    3, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor operations\n",
        "\n",
        "\n",
        "1.   Reshaping tensors\n",
        "2.   Squeezing and Un-squeezing of tensors\n",
        "3.   Concatenating a tensors\n",
        "4.   Flattening of tensors\n",
        "5.   Arithmetic operations\n",
        "\n"
      ],
      "metadata": {
        "id": "UJbaVrh0Y2Hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Reshaping tensors\n",
        "\n",
        "# Step 1: Initialize a list with 20 elements\n",
        "original_list = list(range(1, 21))\n",
        "\n",
        "# Step 2: Transform the list into a PyTorch tensor\n",
        "tensor_data = torch.tensor(original_list)\n",
        "\n",
        "# Display the original list and the tensor\n",
        "print(\"Original List:\", original_list)\n",
        "print(\"Tensor:\", tensor_data)\n",
        "\n",
        "# Reshaping Examples:\n",
        "# Example 1: Reshape to a 4x5 matrix\n",
        "reshaped_tensor_4x5 = tensor_data.reshape(4, 5)\n",
        "print(\"\\nReshaped Tensor (4x5):\")\n",
        "print(reshaped_tensor_4x5)\n",
        "\n",
        "# Example 2: Reshape to a 2x10 matrix\n",
        "reshaped_tensor_2x10 = tensor_data.view(2, 10)\n",
        "print(\"\\nReshaped Tensor (2x10):\")\n",
        "print(reshaped_tensor_2x10)\n",
        "\n",
        "\n",
        "#check the size and the shape of the tensor\n",
        "print(\"size, shape:\", reshaped_tensor_4x5.size(), reshaped_tensor_4x5.shape)\n",
        "\n",
        "#check the len of the list\n",
        "print(\"len:\", len(reshaped_tensor_4x5)) #it returns the number of rows\n",
        "\n",
        "#find the number of elements\n",
        "print(\"number of elements:\",reshaped_tensor_4x5.numel())"
      ],
      "metadata": {
        "id": "mB82qpI5Y7CC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6485c5-6884-4cef-a419-23befd1ff244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original List: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Tensor: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
            "        19, 20])\n",
            "\n",
            "Reshaped Tensor (4x5):\n",
            "tensor([[ 1,  2,  3,  4,  5],\n",
            "        [ 6,  7,  8,  9, 10],\n",
            "        [11, 12, 13, 14, 15],\n",
            "        [16, 17, 18, 19, 20]])\n",
            "\n",
            "Reshaped Tensor (2x10):\n",
            "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
            "        [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]])\n",
            "size, shape: torch.Size([4, 5]) torch.Size([4, 5])\n",
            "len: 4\n",
            "number of elements: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Squeezing and Un-squeezing of tensors\n",
        "# Example 1: Squeeze operation (remove dimensions with size 1)\n",
        "tensor_data_r = tensor_data.reshape(1,20)\n",
        "squeezed_tensor = tensor_data_r.squeeze()\n",
        "\n",
        "# Example 2: Unsqueeze operation (add a dimension with size 1)\n",
        "unsqueezed_tensor = tensor_data_r.unsqueeze(0)  # Adds a dimension at position 0\n",
        "\n",
        "# Display original, squeezed, and unsqueezed tensors\n",
        "print(\"Original Tensor:\")\n",
        "print(tensor_data_r, tensor_data_r.shape)\n",
        "\n",
        "print(\"\\nSqueezed Tensor:\")\n",
        "print(squeezed_tensor, squeezed_tensor.shape)\n",
        "\n",
        "print(\"\\nUnsqueezed Tensor:\")\n",
        "print(unsqueezed_tensor, unsqueezed_tensor.shape)"
      ],
      "metadata": {
        "id": "VcnFTO8eaPAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1e1736-8cda-4793-9783-e34fcd3cb1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
            "         19, 20]]) torch.Size([1, 20])\n",
            "\n",
            "Squeezed Tensor:\n",
            "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
            "        19, 20]) torch.Size([20])\n",
            "\n",
            "Unsqueezed Tensor:\n",
            "tensor([[[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "          18, 19, 20]]]) torch.Size([1, 1, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Concatenating a tensors\n",
        "\n",
        "tensor_1 = torch.tensor([\n",
        "                         [0,1],\n",
        "                         [2,3]])\n",
        "\n",
        "tensor_2 = torch.tensor([\n",
        "                         [4,5],\n",
        "                         [6,7]])\n",
        "# 1) row-wise concatenation\n",
        "conc_tensor = torch.cat((tensor_1,tensor_2), dim=0) # along axis = 0\n",
        "print(\"concatenated tensor:\", conc_tensor, conc_tensor.size())\n",
        "\n",
        "# 2) column-wise concatenation\n",
        "conc_tensor_2 = torch.cat((tensor_1,tensor_2), dim=1) # along axis = 1\n",
        "print(\"concatenated tensor:\", conc_tensor_2, conc_tensor_2.size())\n",
        "\n",
        "tensor_3 = torch.tensor([\n",
        "                        [10,20,30]])\n",
        "print(\"tensor_3:\", tensor_3, tensor_3.size())\n",
        "# to concatenate tensor_1 and tensor_3 the sizes of tensors must match (tensor_1: size 2x2, tensor_3: size 1x3)"
      ],
      "metadata": {
        "id": "pfzQfAHyaRlm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14db962f-1f4a-435d-981c-21ddb8d37c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "concatenated tensor: tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7]]) torch.Size([4, 2])\n",
            "concatenated tensor: tensor([[0, 1, 4, 5],\n",
            "        [2, 3, 6, 7]]) torch.Size([2, 4])\n",
            "tensor_3: tensor([[10, 20, 30]]) torch.Size([1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Flattening of tensors\n",
        "tensor_flatten = torch.flatten(tensor_1)\n",
        "print(\"tensor_flatten:\", tensor_flatten, tensor_flatten.size())\n",
        "\n",
        "# try to concatenate tensor_1 and tensor_3\n",
        "new_tensor_1 = torch.unsqueeze((tensor_flatten), dim=0)\n",
        "print(\"new_tensor_1:\", new_tensor_1, new_tensor_1.size())\n",
        "\n",
        "conc_tensor_new = torch.cat((new_tensor_1,tensor_3), dim=1)\n",
        "print(\"conc_tensor_new:\", conc_tensor_new, conc_tensor_new.size())\n",
        "\n",
        "# Transpose tensor_3\n",
        "tensor_3_transposed = tensor_3.t()\n",
        "print(\"tensor_3_transposed:\", tensor_3_transposed, tensor_3_transposed.size())"
      ],
      "metadata": {
        "id": "63ltY4_uaTYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa93198-7f71-4387-c5e7-9fbc702dca02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_flatten: tensor([0, 1, 2, 3]) torch.Size([4])\n",
            "new_tensor_1: tensor([[0, 1, 2, 3]]) torch.Size([1, 4])\n",
            "conc_tensor_new: tensor([[ 0,  1,  2,  3, 10, 20, 30]]) torch.Size([1, 7])\n",
            "tensor_3_transposed: tensor([[10],\n",
            "        [20],\n",
            "        [30]]) torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Arithmetic operation\n",
        "\n",
        "# 1) sum\n",
        "print(\"original tensors:\", tensor_1, tensor_2)\n",
        "sum_tensor = tensor_1 + tensor_2 # element-wise operations\n",
        "print(\"sum:\", sum_tensor)\n",
        "\n",
        "# Note: element-wise operations can occur only on same size tensor and is scalar component\n",
        "\n",
        "# 2) subtraction\n",
        "sub_tensor = tensor_1 - tensor_2\n",
        "print(\"subtration:\", sub_tensor)\n",
        "\n",
        "# 3) multiplication\n",
        "mul_tensor= tensor_1*tensor_2\n",
        "print(\"multiplication:\", mul_tensor)\n",
        "\n",
        "# 4) division\n",
        "div_tensor = tensor_1 / tensor_2\n",
        "print(\"division:\", div_tensor)"
      ],
      "metadata": {
        "id": "dHFeejL6KGZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96fe4921-0bb8-462f-d2e4-0a0aed9a1e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original tensors: tensor([[0, 1],\n",
            "        [2, 3]]) tensor([[4, 5],\n",
            "        [6, 7]])\n",
            "sum: tensor([[ 4,  6],\n",
            "        [ 8, 10]])\n",
            "subtration: tensor([[-4, -4],\n",
            "        [-4, -4]])\n",
            "multiplication: tensor([[ 0,  5],\n",
            "        [12, 21]])\n",
            "division: tensor([[0.0000, 0.2000],\n",
            "        [0.3333, 0.4286]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question: how we can add 11 to the element in position row 1, column 2 of tensor_1?\n"
      ],
      "metadata": {
        "id": "QzVImvB3LOjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "984b1233-2445-4dd0-bccb-9bf0db79b413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor_1: torch.Size([2, 2])\n",
            "tensor([[ 0, 12],\n",
            "        [ 2,  3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparision operations**: it is a type of element-wise comparision, where the result is given out as a boolean of either 0 (False) or 1 (True)\n"
      ],
      "metadata": {
        "id": "bnB7J9KGMNzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[10,20,30],\n",
        "                  [40,50,60]])\n",
        "print(\"t:\", t, t.size())\n",
        "\n",
        "equal_to = t.eq(10)\n",
        "print(\"equal to:\", equal_to)\n",
        "\n",
        "greater_than_equal_to = t.ge(30)\n",
        "print(\"greater than equal to:\", greater_than_equal_to)\n",
        "\n",
        "greater_than = t.gt(30)\n",
        "print(\"greater than:\", greater_than)\n",
        "\n",
        "less_than_equal_to = t.le(20)\n",
        "print(\"less than equal to:\", less_than_equal_to)\n",
        "\n",
        "less_than = t.lt(20)\n",
        "print(\"less than:\", less_than)"
      ],
      "metadata": {
        "id": "eFY3R_tWOGih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b64d45-1e46-418c-8e01-a71fcde78d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([[10, 20, 30],\n",
            "        [40, 50, 60]]) torch.Size([2, 3])\n",
            "equal to: tensor([[ True, False, False],\n",
            "        [False, False, False]])\n",
            "greater than equal to: tensor([[False, False,  True],\n",
            "        [ True,  True,  True]])\n",
            "greater than: tensor([[False, False, False],\n",
            "        [ True,  True,  True]])\n",
            "less than equal to: tensor([[ True,  True, False],\n",
            "        [False, False, False]])\n",
            "less than: tensor([[ True, False, False],\n",
            "        [False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some useful functions:"
      ],
      "metadata": {
        "id": "4rNXgpFHRTya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"t:\", t, t.size())\n",
        "\n",
        "# absolute value\n",
        "print(\"abs value:\",t.abs())\n",
        "\n",
        "# square root\n",
        "print(\"square root:\",t.sqrt())\n",
        "\n",
        "# negation\n",
        "print(\"negation:\",t.neg())\n",
        "\n",
        "# mean\n",
        "# to calculate the mean, the tensor dtype must be either a floating point or complex dtype\n",
        "# Convert the tensor to float32\n",
        "t_float = t.float()\n",
        "\n",
        "print(\"mean:\", t_float.mean())\n",
        "\n",
        "#std\n",
        "print(\"std:\", t_float.std())\n",
        "\n",
        "# sum at certain columns/rows\n",
        "print(\"sum row 0:\", t[0].sum())\n",
        "print(\"sum row 1:\", t[1].sum())\n",
        "\n",
        "print(\"sum each row\", t.sum(dim=0))\n",
        "print(\"sum each column\", t.sum(dim=1))\n",
        "\n",
        "# find the max value, min value\n",
        "print(\"max:\", t.max())\n",
        "print(\"max value in row 1:\", t[0].max())\n",
        "print(\"min:\", t.min())\n",
        "print(\"min value in column 1:\", t[:, 0].min())\n",
        "print(\"index of the max value:\", t.argmax()) #it flatten the tensor\n",
        "print(\"index of the max value:\", torch.argmax(t, dim=1).numpy()) #need to specify the dimension"
      ],
      "metadata": {
        "id": "oBEdD1IeSOAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8a8f43-7517-4916-e9a4-9411ba883b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([[10, 20, 30],\n",
            "        [40, 50, 60]]) torch.Size([2, 3])\n",
            "abs value: tensor([[10, 20, 30],\n",
            "        [40, 50, 60]])\n",
            "square root: tensor([[3.1623, 4.4721, 5.4772],\n",
            "        [6.3246, 7.0711, 7.7460]])\n",
            "negation: tensor([[-10, -20, -30],\n",
            "        [-40, -50, -60]])\n",
            "mean: tensor(35.)\n",
            "std: tensor(18.7083)\n",
            "sum row 0: tensor(60)\n",
            "sum row 1: tensor(150)\n",
            "sum each row tensor([50, 70, 90])\n",
            "sum each column tensor([ 60, 150])\n",
            "max: tensor(60)\n",
            "max value in row 1: tensor(30)\n",
            "min: tensor(10)\n",
            "min value in column 1: tensor(10)\n",
            "index of the max value: tensor(5)\n",
            "index of the max value: [2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Moving tensors to the GPU\n",
        "\n",
        "PyTorch tensors also can be stored in a different kind of processor: a Graphics Processing Unit (GPU). Every PyTorch tensor can be transferred to (one of) the GPU(s) in order to perform massively parallel, fast computations. All operations that will be performed on the tensor will be carried out using the GPU-specific routines that come with PyTorch."
      ],
      "metadata": {
        "id": "DSeuPYscuCLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "\n",
        "#Create a tensor to GPU\n",
        "tensor_gpu = torch.tensor([[1,2,3], [0.1,0.2,0.3]], device='cuda')\n",
        "\n",
        "# Print the memory usage of the tensor 't'\n",
        "print(\"Memory Allocated for 't':\", sys.getsizeof(t) / (1024 ** 2), \"MB\")\n",
        "\n",
        "# Move the tensor to GPU\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    gpu_tensor = t.to('cuda')\n",
        "    # Alternatively, you can use gpu_tensor = t.cuda()\n",
        "\n",
        "    # Print the tensors to verify the move\n",
        "    print(\"CPU Tensor:\", t)\n",
        "    print(\"GPU Tensor:\", gpu_tensor)\n",
        "\n",
        "     # Check GPU memory usage\n",
        "    print(\"GPU Memory Allocated:\", torch.cuda.memory_allocated() / (1024 ** 2), \"MB\")\n",
        "    print(\"GPU Max Memory Allocated:\", torch.cuda.max_memory_allocated() / (1024 ** 2), \"MB\")\n",
        "\n",
        "else:\n",
        "    print(\"CUDA not available. Unable to move tensor to GPU.\")"
      ],
      "metadata": {
        "id": "QTcYl0wMuJ1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2249736d-526e-4521-d0ca-b905b0c3325a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory Allocated for 't': 8.392333984375e-05 MB\n",
            "CPU Tensor: tensor([[10, 20, 30],\n",
            "        [40, 50, 60]])\n",
            "GPU Tensor: tensor([[10, 20, 30],\n",
            "        [40, 50, 60]], device='cuda:0')\n",
            "GPU Memory Allocated: 11.44677734375 MB\n",
            "GPU Max Memory Allocated: 11.44677734375 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Operations on GPU\n",
        "\n",
        "import time\n",
        "\n",
        "# Create tensors on CPU\n",
        "cpu_tensor1 = torch.randn(1000, 1000)\n",
        "cpu_tensor2 = torch.randn(1000, 1000)\n",
        "\n",
        "# Move tensors to GPU\n",
        "gpu_tensor1 = cpu_tensor1.to('cuda')\n",
        "gpu_tensor2 = cpu_tensor2.to('cuda')\n",
        "\n",
        "# Measure time for element-wise addition on CPU\n",
        "start_time = time.time()\n",
        "result_cpu = cpu_tensor1 + cpu_tensor2\n",
        "print(\"Time on CPU:\", time.time() - start_time)\n",
        "\n",
        "# Measure time for element-wise addition on GPU\n",
        "start_time = time.time()\n",
        "result_gpu = gpu_tensor1 + gpu_tensor2\n",
        "print(\"Time on GPU:\", time.time() - start_time)"
      ],
      "metadata": {
        "id": "5mNiZRnIlh9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8c69b2-e6ba-4dd0-918c-5308d6f76a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time on CPU: 0.002713918685913086\n",
            "Time on GPU: 0.0012989044189453125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Memory Management\n",
        "\n",
        "# Create tensors on GPU\n",
        "tensor1 = torch.randn(1000, 1000, device='cuda')\n",
        "tensor2 = torch.randn(1000, 1000, device='cuda')\n",
        "\n",
        "# Perform operations on GPU\n",
        "result_tensor = tensor1 + tensor2\n",
        "\n",
        "# Free GPU memory\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "3QXQb68SltMB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}